# Big Data Analytics in the Cloud 
This is a big data analysis project using Hadoop which hosted in AWS EC2. This project involved comparing the conventinal method using Python and cloud method using Hadoop on AWS EC2. The frameworks used in Hadoop include Apache Hive and Pyspark. The analysis conducted are word count, length of word, sentiment analysis and compression ratio. 

This folder consists of three folders:
1. Conventional Method using Python
2. MapReduce to perform wordcount using Java and command lines to run on EC2.
3. Hive_Spark that consists of codes and guides to run the preprocessing and different data analysis. 

If you are interested in the guide to perform these analysis, please refer to instruction in 'Hive_Spark' and 'mapreduce'. 